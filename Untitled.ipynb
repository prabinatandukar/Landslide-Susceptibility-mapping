{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e77289-fc25-41f1-b8d3-3a8b866c028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from glob import glob,iglob\n",
    "from osgeo import gdal , gdal_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from write_geotif import CreateGeoTiff\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib \n",
    "import earthpy.plot as ep\n",
    "\n",
    "data_org=pd.read_csv(\"point_final.csv\",delimiter=\";\")\n",
    "\n",
    "data=data_org.copy()\n",
    "data=data.replace(\",\",\".\",regex=True)\n",
    "\n",
    "data.dtypes\n",
    "\n",
    "data=data.iloc[:,1:]\n",
    "\n",
    "# Separate features and target variable\n",
    "X=data.drop('Landslide', axis=1).copy()\n",
    "y=data.loc[:,'Landslide'].copy()\n",
    "\n",
    "X.head()\n",
    "\n",
    "y.head()\n",
    "\n",
    "\n",
    "X=X.astype(float)\n",
    "X.dtypes\n",
    "\n",
    "#!!!!!uncomment when you have your aspect as categorical/factor variable fro example 1,2,3,4.....\n",
    "X['aspect']=X['aspect'].astype(str)\n",
    "X['LULC']=X['LULC'].astype(str)\n",
    "\n",
    "y.dtypes\n",
    "\n",
    "cols_obj=X.columns[X.dtypes=='object'].values.tolist()\n",
    "cols_obj\n",
    "X_encoded=pd.get_dummies(X,columns=cols_obj)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_encoded,y, random_state=6768, train_size=0.70, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "cols_obj\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "X_encoded.columns\n",
    "\n",
    "## XGBOOST\n",
    "\n",
    "\n",
    "clf_xgb=xgb.XGBClassifier(objective='binary:logistic', missing=np.nan,eval_metric='aucpr', early_stopping_rounds=10,seed=42)\n",
    "\n",
    "clf_xgb.fit(X_train,y_train,verbose=True,eval_set=[(X_test,y_test)])\n",
    "\n",
    "\n",
    "class_mapper={0:\"No\", 1:\"Yes\"}\n",
    "\n",
    "class_mapper.keys()\n",
    "\n",
    "class_mapper.values()\n",
    "\n",
    "sns.set(style=\"white\",font_scale=1.4, rc={\"font.weight\": \"bold\"})\n",
    "sns.set_style(style=\"white\")\n",
    "#cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.keys()))\n",
    "fig,ax=plt.subplots(figsize=(10,5))\n",
    "cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.values()),cmap=\"Greys\")\n",
    "cm.fit(X_train,y_train)\n",
    "cm.score(X_test,y_test)\n",
    "cm.show()\n",
    "\n",
    "param_grid={'max_depth':[3,4,5],\n",
    "    'learning_rate':[0.1,0.05,0.01],\n",
    "    'gamma':[0,0.25,1.0],\n",
    "    'reg_lambda':[0,1.0,10.0],\n",
    "    'scale_pos_weight':[1,3,5]}\n",
    "\n",
    "optimal_params=GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', seed=42,subsample=0.9,eval_metric='aucpr',early_stopping_rounds=10),\n",
    "                           param_grid=param_grid,verbose=2,n_jobs=16,cv=5)\n",
    "\n",
    "optimal_params.fit(X_train,y_train,\n",
    "                   verbose=True,\n",
    "                   eval_set=[(X_test,y_test)])\n",
    "\n",
    "optimal_params.best_params_     \n",
    "\n",
    "clf_xgb=xgb.XGBClassifier(objective='binary:logistic', missing=0,eval_metric='aucpr', early_stopping_rounds=10,seed=4442,\n",
    "                          **optimal_params.best_params_,subsample=0.9)\n",
    "\n",
    "\n",
    "clf_xgb.fit(X_train,y_train,verbose=True,eval_set=[(X_test,y_test)])\n",
    "       \n",
    "X_train \n",
    "cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.values()))\n",
    "#cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.keys()),cmap=\"Greys\")\n",
    "cm.fit(X_train,y_train)\n",
    "cm.score(X_test,y_test)\n",
    "cm.show()                              \n",
    "\n",
    "param_grid={'max_depth':[3,4,5],\n",
    "    'learning_rate':[0.1,0.05,0.01],\n",
    "    'gamma':[0,0.25,1.0],\n",
    "    'reg_lambda':[0,1.0,10.0],\n",
    "    'scale_pos_weight':[1,3,5]}\n",
    "\n",
    "optimal_params=GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', seed=42,subsample=0.9,eval_metric='aucpr',early_stopping_rounds=10),\n",
    "                           param_grid=param_grid,verbose=2,n_jobs=16,cv=5)\n",
    "\n",
    "optimal_params.fit(X_train,y_train,\n",
    "                   verbose=True,\n",
    "                   eval_set=[(X_test,y_test)])\n",
    "\n",
    "optimal_params.best_params_\n",
    "clf_xgb=xgb.XGBClassifier(objective='binary:logistic', missing=0,eval_metric='aucpr', early_stopping_rounds=10,seed=4442,\n",
    "                          **optimal_params.best_params_,subsample=0.9)\n",
    "clf_xgb.fit(X_train,y_train,verbose=True,eval_set=[(X_test,y_test)])\n",
    "X_train\n",
    "\n",
    "optimal_params.best_params_\n",
    "\n",
    "clf_xgb=xgb.XGBClassifier(objective='binary:logistic', missing=0,eval_metric='aucpr', early_stopping_rounds=10,seed=4442,\n",
    "                          **optimal_params.best_params_,subsample=0.9)\n",
    "\n",
    "\n",
    "clf_xgb.fit(X_train,y_train,verbose=True,eval_set=[(X_test,y_test)])\n",
    "\n",
    "X_train\n",
    "\n",
    "cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.values()))\n",
    "#cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.keys()),cmap=\"Greys\")\n",
    "cm.fit(X_train,y_train)\n",
    "cm.score(X_test,y_test)\n",
    "cm.show()\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(25,15))\n",
    "viz = FeatureImportances(clf_xgb, relative=True, ax=ax)\n",
    "\n",
    "viz.fit(X_train, y_train)\n",
    "ax.set(title=\"Relative features importance\", ylabel=\"Features\", xlabel=\"Relative Importance\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "original_palette = sns.color_palette(\"Greys\")\n",
    "\n",
    "# Create a reversed version of the palette\n",
    "reversed_palette = original_palette[::-1]\n",
    "\n",
    " visualizer = ClassificationReport(clf_xgb, classes=list(class_mapper.values()), support=False,cmap=reversed_palette)\n",
    "\n",
    "\n",
    "visualizer = ClassificationReport(clf_xgb, classes=list(class_mapper.values()), support=False,cmap=reversed_palette)\n",
    "sns.set(style=\"white\",font_scale=2.5, rc={\"font.weight\": \"bold\"})\n",
    "sns.set_style(style=\"white\")\n",
    "#cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.keys()))\n",
    "fig,ax=plt.subplots(figsize=(25,15))\n",
    "\n",
    "visualizer.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show(outpath=\"./accuracy_assessment.png\")    \n",
    "fig.tight_layout()\n",
    "\n",
    "## prediction for the entire image \n",
    "\n",
    "full_data_files=glob(\"./data/*.tif\")\n",
    "\n",
    "full_data_files\n",
    "\n",
    "files_sorted=['./data\\\\clip_dtm.tif',\n",
    "            './data\\\\slope1_clip.tif',\n",
    "             './data\\\\LULC_clip1.tif',\n",
    "             './data\\\\prof_cur_clip.tif',\n",
    "             './data\\\\plan_cur_clip.tif',\n",
    "             './data\\\\road_clip.tif',\n",
    "             './data\\\\river_clip.tif',\n",
    "             './data\\\\NDVI_clip.tif',\n",
    "            './data\\\\rain_clip.tif',\n",
    "             './data\\\\aspect_clip.tif']\n",
    "\n",
    "\n",
    "X_encoded.head()\n",
    "\n",
    "X_encoded.columns\n",
    "\n",
    "full_data_array=[]\n",
    "subset=(0,0, 6860,4064)\n",
    "for i in files_sorted:\n",
    "    full_data_array.append(gdal.Open(i).ReadAsArray(*subset))\n",
    "\n",
    "#temp=gdal.Open(files_sorted[3])\n",
    "#temp=temp.ReadAsArray()\n",
    "\n",
    "len(full_data_array)\n",
    "\n",
    "full_data_array\n",
    "\n",
    "#convert back to array\n",
    "#np.array([full_data_array[1]]).shape # to convert 2D dimension to 3D array to make concatenation possible \n",
    "#full_data_array=np.concatenate(full_data_array, axis =1)\n",
    "\n",
    "full_data_array=np.stack(full_data_array)\n",
    "\n",
    "dimension=full_data_array.shape\n",
    "dimension\n",
    "\n",
    "full_data_array=full_data_array.reshape(10,(dimension[1]*dimension[2]))\n",
    "\n",
    "full_data_array.shape\n",
    "\n",
    "full_data_array=full_data_array.swapaxes(0,1)\n",
    "full_data_array.shape\n",
    "\n",
    "#for longitude and latitude \n",
    "meta_data=gdal.Open(files_sorted[2])\n",
    "\n",
    "geotransform=meta_data.GetGeoTransform()\n",
    "geotransform\n",
    "\n",
    "meta_data.GetProjection()\n",
    "\n",
    "band_description=meta_data.GetRasterBand(1)\n",
    "\n",
    "band_description.XSize\n",
    "\n",
    "band_description.YSize\n",
    "\n",
    "long=[geotransform[0]+ i for i in range(band_description.XSize-1)]\n",
    "lat=[ geotransform[3] -i for i in range (band_description.YSize-1) ]\n",
    "\n",
    "len(long)\n",
    "\n",
    "len(lat)\n",
    "\n",
    "\n",
    "\n",
    "#full_data_array[100,1]\n",
    "\n",
    "#full_data_array[100,2]\n",
    "\n",
    "#full_data_array[100,3]\n",
    "\n",
    "#np.c_[np.arange(1,10).ravel(),np.arange(100,109).ravel()]\n",
    "\n",
    "\n",
    "#r,c=np.meshgrid(np.arange(1,10),np.arange(100,109))\n",
    "\n",
    "\n",
    "#r\n",
    "#np.c_[r.ravel(),c.ravel()]\n",
    "\n",
    "xx,yy=np.meshgrid(np.array(long),np.array(lat))\n",
    "#xx_yy_matrix=np.vstack((np.ravel(xx), np.ravel(yy)))\n",
    "xx_yy_matrix=np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "xx_yy_matrix.shape\n",
    "\n",
    "full_data_array.shape\n",
    "\n",
    "full_data_array=np.hstack((xx_yy_matrix,full_data_array))\n",
    "\n",
    "full_data_array.shape\n",
    "\n",
    "full_data_array[:,5]\n",
    "\n",
    "full_data_array_df=pd.DataFrame(full_data_array, columns=X.columns)\n",
    "\n",
    "full_data_array_df\n",
    "\n",
    "full_data_array_df['aspect']=full_data_array_df['aspect'].astype(str)\n",
    "full_data_array_df['LULC']=full_data_array_df['LULC'].astype(str)\n",
    "cols_obj_full=full_data_array_df.columns[full_data_array_df.dtypes=='object'].values.tolist()\n",
    "cols_obj_full\n",
    "full_data_array_df_encoded=pd.get_dummies(full_data_array_df,columns=cols_obj_full)\n",
    "\n",
    "full_data_array_df_encoded.columns\n",
    "\n",
    "#full_data_array_df[\"LULC\"].unique()\n",
    "\n",
    "X_encoded.columns\n",
    "\n",
    "# List of missing columns in full_data_array_df_encoded\n",
    "#missing_columns = ['LULC_0.0', 'LULC_1.0', 'LULC_3.0', 'LULC_6.0', 'LULC_7.0', 'aspect_0.0']\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X_encoded and full_data_array_df_encoded are your DataFrames\n",
    "missing_columns = [c for c in X_encoded.columns if c not in full_data_array_df_encoded.columns]\n",
    "missing_columns\n",
    "\n",
    "# Add missing columns to full_data_array_df_encoded and fill with zeros\n",
    "for col in missing_columns:\n",
    "    full_data_array_df_encoded[col] = False\n",
    "\n",
    "full_data_array_df_encoded.columns\n",
    "#X_encoded.shape\n",
    "#==X_encoded.columns\n",
    "\n",
    "#filter/subset columns to confrom with ur training data\n",
    "full_data_array_df_encoded=full_data_array_df_encoded[X_encoded.columns]\n",
    "\n",
    " \n",
    "# Reordering columns to match the model's feature order\n",
    "full_data_array_df_encoded = full_data_array_df_encoded[X_encoded.columns]\n",
    "\n",
    "#np.all(full_data_array_df_encoded.columns==X_encoded.columns)\n",
    "\n",
    "\n",
    "X_encoded.columns\n",
    "\n",
    "# Making predictions using the XGBoost model\n",
    "#predictions = clf_xgb.predict(full_data_array_df_encoded)\n",
    "predictions = clf_xgb.predict_proba(full_data_array_df_encoded)\n",
    "#probability of occurence \n",
    "predictions_occ=predictions[:,1]\n",
    "l=predictions_occ.reshape(dimension[1:])\n",
    "\n",
    "predictions_occ\n",
    "\n",
    "dimension[1]*dimension[2]\n",
    "\n",
    "ep.plot_bands(l)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(15,15))\n",
    "plt.imshow(l)\n",
    "\n",
    "\"\"\"\n",
    "def CreateGeoTiff(Name, Array, DataType, NDV,bandnames=None,ref_image=None, \n",
    "                  GeoT=None, Projection=None):\n",
    "    # If it's a 2D image we fake a third dimension:\n",
    "    if len(Array.shape)==2:\n",
    "        Array=np.array([Array])\n",
    "    if ref_image==None and (GeoT==None or Projection==None):\n",
    "        raise RuntimeWarning('ref_image or settings required.')\n",
    "    if bandnames != None:\n",
    "        if len(bandnames) != Array.shape[0]:\n",
    "            raise RuntimeError('Need {} bandnames. {} given'\n",
    "                               .format(Array.shape[0],len(bandnames)))\n",
    "    else:\n",
    "        bandnames=['Band {}'.format(i+1) for i in range(Array.shape[0])]\n",
    "    if ref_image!= None:\n",
    "        refimg=gdal.Open(ref_image)\n",
    "        GeoT=refimg.GetGeoTransform()\n",
    "        Projection=refimg.GetProjection()\n",
    "    driver= gdal.GetDriverByName('GTIFF')\n",
    "    Array[np.isnan(Array)] = NDV\n",
    "    DataSet = driver.Create(Name, \n",
    "            Array.shape[2], Array.shape[1], Array.shape[0], DataType)\n",
    "    DataSet.SetGeoTransform(GeoT)\n",
    "    DataSet.SetProjection( Projection)\n",
    "    for i, image in enumerate(Array, 1):\n",
    "        DataSet.GetRasterBand(i).WriteArray( image )\n",
    "        DataSet.GetRasterBand(i).SetNoDataValue(NDV)\n",
    "        DataSet.SetDescription(bandnames[i-1])\n",
    "    DataSet.FlushCache()\n",
    "    return Name\n",
    "\"\"\"\n",
    "\n",
    "gdal_type=gdal_array.NumericTypeCodeToGDALTypeCode(l.dtype)\n",
    "gdal_type\n",
    "\n",
    "CreateGeoTiff(\"./classification/test.tif\",l,gdal_type,-9999,[\"Band_1\"],GeoT=meta_data.GetGeoTransform(),Projection=meta_data.GetProjection())\n",
    "\n",
    "## RandomForest\n",
    "\n",
    "#goto\n",
    "clf_rf=RandomForestClassifier(n_estimators=300, oob_score=True)\n",
    "\n",
    "\n",
    "clf_rf.fit(X_train,y_train)\n",
    "\n",
    "sns.set(style=\"white\",font_scale=1.4, rc={\"font.weight\": \"bold\"})\n",
    "sns.set_style(style=\"white\")\n",
    "#cm = ConfusionMatrix(clf_xgb, classes=list(class_mapper.keys()))\n",
    "fig,ax=plt.subplots(figsize=(10,5))\n",
    "cm_rf = ConfusionMatrix(clf_rf, classes=list(class_mapper.values()),cmap=\"Greys\")\n",
    "cm_rf.fit(X_train,y_train)\n",
    "cm_rf.score(X_test,y_test)\n",
    "cm_rf.show()\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(25,15))\n",
    "viz_rf = FeatureImportances(clf_rf, relative=True, ax=ax)\n",
    "\n",
    "viz_rf.fit(X_train, y_train)\n",
    "ax.set(title=\"Relative features importance\", ylabel=\"Features\", xlabel=\"Relative Importance\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "visualizer_rf = ClassificationReport(clf_rf, classes=list(class_mapper.values()), support=False,cmap=reversed_palette)\n",
    "sns.set(style=\"white\",font_scale=2.5, rc={\"font.weight\": \"bold\"})\n",
    "sns.set_style(style=\"white\")\n",
    "fig,ax=plt.subplots(figsize=(25,15))\n",
    "visualizer_rf.fit(X_train, y_train)        # Fit the visualizer and the model\n",
    "visualizer_rf.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer_rf.show(outpath=\"./accuracy_assessment_random_forest.png\")    \n",
    "fig.tight_layout()\n",
    "\n",
    "# Making predictions using the XGBoost model\n",
    "#predictions = clf_xgb.predict(full_data_array_df_encoded)\n",
    "predictions_rf = clf_rf.predict_proba(full_data_array_df_encoded)\n",
    "#probability of occurence \n",
    "predictions_occ_rf=predictions[:,1]\n",
    "l_rf=predictions_occ_rf.reshape(dimension[1:])\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(15,15))\n",
    "plt.imshow(l_rf)\n",
    "\n",
    "\n",
    "\n",
    "CreateGeoTiff(\"./classification/test_rf.tif\",l_rf,gdal_type,-9999,[\"Band_1\"],GeoT=meta_data.GetGeoTransform(),Projection=meta_data.GetProjection())\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=1658, oob_score=True)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier with the best parameters\n",
    "best_rf_clf = RandomForestClassifier(random_state=42, oob_score=True, **grid_search.best_params_)\n",
    "\n",
    "# Train the classifier\n",
    "best_rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate the NgBoost classifier\n",
    "clf_ngb = NGBClassifier(n_estimators=100, learning_rate=0.01, verbose=True, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_ngb.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "y_prob_ngb = clf_ngb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance (e.g., using ROC AUC)\n",
    "auc_ngb = roc_auc_score(y_test, y_prob_ngb)\n",
    "print(\"ROC AUC Score (NgBoost):\", auc_ngb)\n",
    "\n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate the NgBoost classifier\n",
    "clf_ngb = NGBClassifier(n_estimators=100, learning_rate=0.01, verbose=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf_ngb.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "y_prob_ngb = clf_ngb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance (e.g., using ROC AUC)\n",
    "auc_ngb = roc_auc_score(y_test, y_prob_ngb)\n",
    "print(\"ROC AUC Score (NgBoost):\", auc_ngb)\n",
    "\n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "optimal_params.fit(X_train,y_train,\n",
    "                   verbose=True,\n",
    "                   eval_set=[(X_test,y_test)])\n",
    "\n",
    "optimal_params.best_params_  \n",
    "\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you have performed GridSearchCV and stored the results in optimal_params\n",
    "optimal_params = {\n",
    "    \"n_estimators\": 100,  # Example parameter, replace with actual ones\n",
    "    \"learning_rate\": 0.01,  # Example parameter, replace with actual ones\n",
    "    # Add other best parameters found by GridSearchCV\n",
    "}\n",
    "\n",
    "# Instantiate the NgBoost classifier with best parameters found by GridSearchCV\n",
    "clf_ngb = NGBClassifier(verbose=True, random_state=4442, **optimal_params)\n",
    "\n",
    "# Fit NgBoost classifier to the training data\n",
    "clf_ngb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_ngb = clf_ngb.predict(X_test)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm_ngb = confusion_matrix(y_test, y_pred_ngb)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp_ngb = ConfusionMatrixDisplay(confusion_matrix=cm_ngb)\n",
    "disp_ngb.plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
